### preliminary
## packages
library(jsonlite)
library(data.table)
## remarks
### import top questions
## function to get top questions
get_top_questions <- function(after) {
# base url
base_url <- "https://www.reddit.com/r/AskHistorians/top/.json?sort=top&t=all&limit=100&after="
# get json
questions <- fromJSON(paste0(base_url,after))
# get last id
last_question_ind <- nrow(questions[["data"]][["children"]])
last_id <- questions[["data"]][["children"]][["data"]][["name"]][last_question_ind]
# return
result <- list(questions,last_id)
names(result) <- c("questions","last_id")
return(result) }
## import
questions <- get_top_questions(after = "")
nr_comments <- 10000
while(length(questions) < nr_comments/50)  {
additional_questions <- get_top_questions(after = questions[[length(questions)]])
questions <- c(questions, additional_questions) }
### clean top questions
## remove last ids
questions <- questions[-grep(pattern = "last_id", x = names(questions))]
## information available
names(questions[[1]][["data"]][["children"]][["data"]])
## extract interesting information
# interesting variables
questions[[1]][["data"]][["children"]][["data"]][["ups"]]
interesting_var <- c("selftext","gilded","author","score","over_18","edited","link_flair_css_class",
"author_flair_css_class","archived","url","author_flair_text","title","link_flair_text",
"num_comments","ups")
# extract
interesting_info <- lapply(questions,
function(x) {
df <- as.data.frame(lapply(interesting_var,
function(y) x[["data"]][["children"]][["data"]][[y]]))
names(df) <- interesting_var
return(df)
}
)
## bind as dataframe
top_questions <- rbindlist(interesting_info)
### preliminary
## packages
library(jsonlite)
library(data.table)
## remarks
### import top questions
## function to get top questions
get_top_questions <- function(after) {
# base url
base_url <- "https://www.reddit.com/r/AskHistorians/top/.json?sort=top&t=all&limit=100&after="
# get json
questions <- fromJSON(paste0(base_url,after))
# get last id
last_question_ind <- nrow(questions[["data"]][["children"]])
last_id <- questions[["data"]][["children"]][["data"]][["name"]][last_question_ind]
# return
result <- list(questions,last_id)
names(result) <- c("questions","last_id")
return(result) }
## import
questions <- get_top_questions(after = "")
nr_comments <- 10000
while(length(questions) < nr_comments/50)  {
additional_questions <- get_top_questions(after = questions[[length(questions)]])
questions <- c(questions, additional_questions) }
### clean top questions
## remove last ids
questions <- questions[-grep(pattern = "last_id", x = names(questions))]
## information available
names(questions[[1]][["data"]][["children"]][["data"]])
## extract interesting information
# interesting variables
questions[[1]][["data"]][["children"]][["data"]][["ups"]]
interesting_var <- c("selftext","gilded","author","score","over_18","edited","link_flair_css_class",
"author_flair_css_class","archived","url","author_flair_text","title","link_flair_text",
"num_comments","ups")
# extract
interesting_info <- lapply(questions,
function(x) {
df <- as.data.frame(lapply(interesting_var,
function(y) x[["data"]][["children"]][["data"]][[y]]))
names(df) <- interesting_var
return(df)
}
)
## bind as dataframe
top_questions <- rbindlist(interesting_info)
interesting_info <- lapply(questions,
function(x) {
df <- as.data.frame(lapply(interesting_var,
function(y) x[["data"]][["children"]][["data"]][[y]]))
names(df) <- interesting_var
return(df)
}
)
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]))
test <- questions
### preliminary
## packages
library(jsonlite)
library(data.table)
## remarks
### import top questions
## function to get top questions
get_top_questions <- function(after) {
# base url
base_url <- "https://www.reddit.com/r/AskHistorians/top/.json?sort=top&t=all&limit=100&after="
# get json
questions <- fromJSON(paste0(base_url,after))
# get last id
last_question_ind <- nrow(questions[["data"]][["children"]])
last_id <- questions[["data"]][["children"]][["data"]][["name"]][last_question_ind]
# return
result <- list(questions,last_id)
names(result) <- c("questions","last_id")
return(result) }
## import
questions <- get_top_questions(after = "")
nr_comments <- 10000
while(length(questions) < nr_comments/50)  {
Sys.sleep(3)
additional_questions <- get_top_questions(after = questions[[length(questions)]])
questions <- c(questions, additional_questions) }
### clean top questions
## remove last ids
questions <- questions[-grep(pattern = "last_id", x = names(questions))]
## information available
names(questions[[1]][["data"]][["children"]][["data"]])
## extract interesting information
# interesting variables
questions[[1]][["data"]][["children"]][["data"]][["ups"]]
interesting_var <- c("selftext","gilded","author","score","over_18","edited","link_flair_css_class",
"author_flair_css_class","archived","url","author_flair_text","title","link_flair_text",
"num_comments","ups")
# extract
interesting_info <- lapply(questions,
function(x) {
df <- as.data.frame(lapply(interesting_var,
function(y) x[["data"]][["children"]][["data"]][[y]]))
names(df) <- interesting_var
return(df)
}
)
## bind as dataframe
top_questions <- rbindlist(interesting_info)
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]))
names(questions[[1]][["data"]][["children"]][["data"]])
lapply(questions, class)
sapply(questions, length)
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]))
questions[[99]][["data"]][["children"]][["data"]][["title"]]
questions[[99]][["data"]][["children"]][["data"]][["subreddit"]]
s
sapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]))
unlist(lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]])))
unlist(sapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]])))
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]] < 99))
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]] == NULL))
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]))
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]) < 99)
sapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]) < 99)
unlist(lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]) < 99))
length(unlist(lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]) < 99)))
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]) < 99)
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]) > 98)
?any
lapply(lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]) > 98), function(y) y == TRUE)
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]) > 98)
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]))
sapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]))
lapply(questions, function(x) nrow(x[["data"]][["children"]][["data"]]))
lapply(questions, function(x) length(x[["data"]]))
lapply(questions, function(x) is.null(nrow(x[["data"]][["children"]][["data"]])))
unlist(lapply(questions, function(x) is.null(nrow(x[["data"]][["children"]][["data"]]))))
length(unlist(lapply(questions, function(x) is.null(nrow(x[["data"]][["children"]][["data"]])))))
questions <- questions[!unlist(lapply(questions, function(x) is.null(nrow(x[["data"]][["children"]][["data"]]))))]
names(questions[[1]][["data"]][["children"]][["data"]])
# interesting variables
questions[[1]][["data"]][["children"]][["data"]][["ups"]]
interesting_var <- c("selftext","gilded","author","score","over_18","edited","link_flair_css_class",
"author_flair_css_class","archived","url","author_flair_text","title","link_flair_text",
"num_comments","ups")
# extract
interesting_info <- lapply(questions,
function(x) {
df <- as.data.frame(lapply(interesting_var,
function(y) x[["data"]][["children"]][["data"]][[y]]))
names(df) <- interesting_var
return(df)
}
)
top_questions <- rbindlist(interesting_info)
View(top_questions)
length(unique(top_questions$title))
### preliminary
## packages
library(jsonlite)
library(data.table)
## remarks
### import top questions
## function to get top questions
get_top_questions <- function(after) {
# base url
base_url <- "https://www.reddit.com/r/AskHistorians/top/.json?sort=top&t=all&limit=100&after="
# get json
questions <- fromJSON(paste0(base_url,after))
# get last id
last_question_ind <- nrow(questions[["data"]][["children"]])
last_id <- questions[["data"]][["children"]][["data"]][["name"]][last_question_ind]
# return
result <- list(questions,last_id)
names(result) <- c("questions","last_id")
return(result) }
## import
questions <- get_top_questions(after = "")
nr_comments <- 1100
while(length(questions) < nr_comments/50)  {
Sys.sleep(3)
additional_questions <- get_top_questions(after = questions[[length(questions)]])
questions <- c(questions, additional_questions) }
### clean top questions
## remove last ids
questions <- questions[-grep(pattern = "last_id", x = names(questions))]
lapply(questions, function(x) is.null(nrow(x[["data"]][["children"]][["data"]])))
### preliminary
## packages
library(jsonlite)
library(data.table)
## remarks
### import top questions
## function to get top questions
get_top_questions <- function(after) {
# base url
base_url <- "https://www.reddit.com/r/AskHistorians/top/.json?sort=top&t=all&limit=100&after="
# get json
questions <- fromJSON(paste0(base_url,after))
# get last id
last_question_ind <- nrow(questions[["data"]][["children"]])
last_id <- questions[["data"]][["children"]][["data"]][["name"]][last_question_ind]
# return
result <- list(questions,last_id)
names(result) <- c("questions","last_id")
return(result) }
## import
questions <- get_top_questions(after = "")
nr_comments <- 1300
while(length(questions) < nr_comments/50)  {
Sys.sleep(3)
additional_questions <- get_top_questions(after = questions[[length(questions)]])
questions <- c(questions, additional_questions) }
### clean top questions
## remove last ids
questions <- questions[-grep(pattern = "last_id", x = names(questions))]
lapply(questions, function(x) is.null(nrow(x[["data"]][["children"]][["data"]])))
## remove empty requests
questions <- questions[!unlist(lapply(questions, function(x) is.null(nrow(x[["data"]][["children"]][["data"]]))))]
## information available
names(questions[[1]][["data"]][["children"]][["data"]])
## extract interesting information
# interesting variables
questions[[1]][["data"]][["children"]][["data"]][["ups"]]
interesting_var <- c("selftext","gilded","author","score","over_18","edited","link_flair_css_class",
"author_flair_css_class","archived","url","author_flair_text","title","link_flair_text",
"num_comments","ups")
# extract
interesting_info <- lapply(questions,
function(x) {
df <- as.data.frame(lapply(interesting_var,
function(y) x[["data"]][["children"]][["data"]][[y]]))
names(df) <- interesting_var
return(df)
}
)
## bind as dataframe
top_questions <- rbindlist(interesting_info)
View(top_questions)
base <- "C:/Users/Isaac/Desktop/data analysis/askhistorians"
### preliminary
## packages
library(jsonlite)
library(data.table)
## remarks
### import top questions
## function to get top questions
get_top_questions <- function(after) {
# base url
base_url <- "https://www.reddit.com/r/AskHistorians/top/.json?sort=top&t=all&limit=100&after="
# get json
questions <- fromJSON(paste0(base_url,after))
# get last id
last_question_ind <- nrow(questions[["data"]][["children"]])
last_id <- questions[["data"]][["children"]][["data"]][["name"]][last_question_ind]
# return
result <- list(questions,last_id)
names(result) <- c("questions","last_id")
return(result) }
## import
questions <- get_top_questions(after = "")
nr_comments <- 1000
while(length(questions) < nr_comments/50)  {
Sys.sleep(3)
additional_questions <- get_top_questions(after = questions[[length(questions)]])
questions <- c(questions, additional_questions) }
### clean top questions
## remove last ids
questions <- questions[-grep(pattern = "last_id", x = names(questions))]
## information available
names(questions[[1]][["data"]][["children"]][["data"]])
## extract interesting information
# interesting variables
questions[[1]][["data"]][["children"]][["data"]][["ups"]]
interesting_var <- c("selftext","gilded","author","score","over_18","edited","link_flair_css_class",
"author_flair_css_class","archived","url","author_flair_text","title","link_flair_text",
"num_comments","ups")
# extract
interesting_info <- lapply(questions,
function(x) {
df <- as.data.frame(lapply(interesting_var,
function(y) x[["data"]][["children"]][["data"]][[y]]))
names(df) <- interesting_var
return(df)
}
)
## bind as dataframe
top_questions <- rbindlist(interesting_info)
### save
write.csv(top_questions, file.path(base,"output","data","top_questions_alltime.csv"))
save(top_questions, file.path(base,"output","data","top_questions_alltime.RData"))
file.path(base,"output","data","top_questions_alltime.RData")
save(top_questions, file.path(base,"output","data","top_questions_alltime.RData"))
save(top_questions, file.path(base,"output","data","top_questions_alltime.RData"))
save(top_questions, file = file.path(base,"output","data","top_questions_alltime.RData"))
View(top_questions)
library(jsonlite)
rm(list = ls())
library(jsonlite)
test <- fromjson("https://www.reddit.com/r/AskHistorians/comments/4xj6fc/michael_phelps_beat_a_2000_year_old_olympic/.json")
test <- fromJSON("https://www.reddit.com/r/AskHistorians/comments/4xj6fc/michael_phelps_beat_a_2000_year_old_olympic/.json")
names(test)
namest(test[["data"]])
names(test[["data"]])
test[["data"]][["modhash"]]
test[["data"]][["after"]]
test[["data"]][["before"]]
names(test[["data"]][["children"]])
temp <- test[["data"]][["children"]][[1]])
temp <- test[["data"]][["children"]][[1]]
View(temp)
View(temp)
temp <- test[["data"]][["children"]][[1]][["data"]]
View(temp)
View(temp)
temp <- test[["data"]][["children"]][[1]][["data"]][["mod_reports"]]
temp[[1]]
temp <- test[["data"]][["children"]][[1]][["data"]]
View(temp)
temp <- test[["data"]][["children"]][[2]]
View(temp)
temp <- test[["data"]][["children"]][[2]][["data"]]
temp <- test[["data"]][["children"]][[2]][["data"]][["replies"]]
### preliminary
## packages
library(jsonlite)
## remarks
top_post <- fromJSON("https://www.reddit.com/r/AskHistorians/comments/4xj6fc/michael_phelps_beat_a_2000_year_old_olympic/.json")
rm(temp)
rm(test)
str(top_post)
class(top_post)
?rapply
X <- list(list(a = pi, b = list(c = 1:1)), d = "a test")
rapply(X, function(x) x, how = "replace")
test <- rapply(X, function(x) x, how = "replace")
test <- rapply(top_post, function(x) names(x) == "data")
test <- rapply(top_post, function(x) names(x))
test <- grep(pattern = "author", x = top_post)
test
test <- rapply(top_post, function(x) grep(pattern = "author", x = x))
test
test <- as.data.frame(top_post)
View(test)
rm(test)
rm(X)
rapply(top_post, names)
names(top_post)
test <- top_post[["data"]][["children"]][[1]][["data"]][["author"]]
test
test <- top_post[[2]][["data"]][["children"]][[1]][["data"]][["author"]]
test <- top_post[["data"]][["children"]][[2]][["data"]][["author"]]
test
test <- top_post[["data"]][["children"]][[3]][["data"]][["author"]]
test <- top_post[["data"]][["children"]][[2]][["data"]][["author"]]
test <- top_post[[1]]
test <- top_post[[1]][[1]]
test
View(top_post)
View(top_post)
test <- top_post[["data.children"]][[2]]
top_post <- fromJSON("https://www.reddit.com/r/AskHistorians/comments/4xj6fc/michael_phelps_beat_a_2000_year_old_olympic/.json")
test <- top_post[["data"]][["children"]][[2]]
test <- top_post[["data"]][["children"]][[2]][["data"]][["replies"]]
rm(test)
names(top_post)
View(top_post)
names(top_post[["data"]])
top_post[["data"]][["modhash"]]
names(top_post[["data"]])
top_post[["data"]][["children"]]
names(top_post[["data"]][["children"]][["data"]])
test <- unlist(top_post)
test
test[1:10]
test[1:100]
test[200:300]
names(test)[200:300]
top_post <- unlist(top_post)
rm(test)
test <- strsplit(names(top_post), split = "\.")
test <- strsplit(names(top_post), split = ".")
test[100]
test <- strsplit(names(top_post), split = "\.")
test <- strsplit(names(top_post), split = "\\.")
test[100]
names(top_post) <- lapply(X = strsplit(names(top_post), split = "\\."),
FUN = function(x) x[length(x)])
names(top_post)[100:200]
grep(pattern = "author", names(top_post))
names(top_post)[grep(pattern = "author", names(top_post))]
names(top_post)[grep(pattern = "score", names(top_post))]
names(top_post)[grep(pattern = "body", names(top_post))]
names(top_post)[grep(pattern = "^body$", names(top_post))]
names(top_post)[grep(pattern = "body\\d+", names(top_post))]
top_post[grep(pattern = "body\\d+", names(top_post))]
top_post[grep(pattern = "body\\d+", names(top_post))][1]
names(top_post[grep(pattern = "body\\d+", names(top_post))][1])
names(top_post[grep(pattern = "body\\d+", names(top_post))])
names(top_post[grep(pattern = "body\\d+|body", names(top_post))])
top_post[grep(pattern = "body\\d+|body", names(top_post))][1]
names(top_post[grep(pattern = "body\\d+|body\\b", names(top_post))])
top_post[grep(pattern = "body\\d+|body\\b", names(top_post))][1]
top_post[grep(pattern = "body\\d+|body\\b", names(top_post))][1]
names(top_post[grep(pattern = "body\\d+|body\\b", names(top_post))])
top_post[grep(pattern = "body\\d+|body\\b", names(top_post))][4]
top_post[grep(pattern = "body\\d+|body\\b", names(top_post))][5]
names(top_post[grep(pattern = "parent_id", names(top_post))])
top_post[grep(pattern = "parent_id", names(top_post))]
### preliminary
## packages
library(jsonlite)
## remarks
### load post
top_post <- fromJSON("https://www.reddit.com/r/AskHistorians/comments/4xj6fc/michael_phelps_beat_a_2000_year_old_olympic/.json?limit=500")
### extract comments
## variables of interest
interesting_var <- c("author","parent_id","score","body","author_flair_css_class","author_flair_text")
## put json comments in searchable format
# just a vector
top_post <- unlist(top_post)
# only end of tree is important
names(top_post) <- lapply(X = strsplit(names(top_post), split = "\\."),
FUN = function(x) x[length(x)])
rm(test)
top_post[grep(pattern = "parent_id", names(top_post))]
length(top_post[grep(pattern = "parent_id", names(top_post))])
top_post[grep(pattern = "body\\d+|body\\b", names(top_post))][1]
length(top_post[grep(pattern = "body\\d+|body\\b", names(top_post))])
### preliminary
## packages
library(jsonlite)
## remarks
### load post
top_post <- fromJSON("https://www.reddit.com/r/AskHistorians/comments/4xj6fc/michael_phelps_beat_a_2000_year_old_olympic/.json?limit=500")
### extract comments
## variables of interest
interesting_var <- c("author","parent_id","score","body","author_flair_css_class","author_flair_text")
## put json comments in searchable format
# just a vector
top_post <- unlist(top_post)
# only end of tree is important
names(top_post) <- lapply(X = strsplit(names(top_post), split = "\\."),
FUN = function(x) x[length(x)])
## turn variables of interest into regex
regex_interesting_var <- paste0(interesting_var,"\\d+|",interesting_var,"\\b")
regex_interesting_var
regex_interesting_var[1]
names(top_post[grep(pattern = regex_interesting_var[1], names(top_post))])
top_post[grep(pattern = regex_interesting_var[1], names(top_post))]
length(top_post[grep(pattern = regex_interesting_var[1], names(top_post))])
length(top_post[grep(pattern = regex_interesting_var[2], names(top_post))])
length(top_post[grep(pattern = regex_interesting_var[3], names(top_post))])
length(top_post[grep(pattern = regex_interesting_var[4], names(top_post))])
length(top_post[grep(pattern = regex_interesting_var[5], names(top_post))])
length(top_post[grep(pattern = regex_interesting_var[6], names(top_post))])
interesting_var[3:4]
grep(pattern = regex_interesting_var[6], names(top_post))
top_post[44:60]
top_post[44:80]
grep(pattern = regex_interesting_var[6], names(top_post))
top_post[219:261]
top_post[219:230]
top_post[219:240]
top_post[219:250]
top_post[219:260]
top_post[219:255]
top_post[219:252]
